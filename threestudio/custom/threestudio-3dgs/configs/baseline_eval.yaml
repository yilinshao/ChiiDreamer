name: "luciddreamer-validation" # layout-eval-validation
tag: "${rmspace:${system.prompt_processor.prompt},_}"
exp_root_dir: "outputs"
seed: 0

data_type: "mvdream-random-multiview-camera-datamodule"
data:
  batch_size: [4, 4]
  n_view: 4
  # 0-4999: 64x64, >=5000: 512x512
  # this drastically reduces VRAM usage as empty space is pruned in early training
  width: [256, 512]
  height: [256, 512]
  resolution_milestones: [300]
  camera_distance_range: [1.3, 1.5]
  fovy_range: [40, 70]
  elevation_range: [-10, 45]
  camera_perturb: 0
  center_perturb: 0
  up_perturb: 0.
  eval_camera_distance: 1.1 # 1.3
  eval_fovy_deg: 70
  eval_elevation_deg: 0
  eval_width: 512
  eval_height: 512
  n_val_views: 8
  rays_d_normalize: false

system_type: "gaussian-splatting-layout-system"
system:
  geometry_type: "gaussian-splatting"
  geometry:
    position_lr: [0, 0.001, 0.00002, 300]
    scale_lr: 0.005
    feature_lr: 0.01
    opacity_lr: 0.05
    rotation_lr: 0.005
    min_opac_prune: 0.05
    prune_interval: 100
    prune_from_iter: 300
    prune_until_iter: 500
    densification_interval: 100
    densify_from_iter: 300
    densify_until_iter: 500
    opacity_reset_interval: 50000000
    densify_grad_threshold: 0.01
    split_thresh: 0.02
    radii2d_thresh: 1000

    pc_init_radius: 0.8
    opacity_init: 0.2
    max_num: 5000000

    optimize_layout: false
    optimize_gaussians: true
    init_from_depth: true
    layout_2d: [[0.125, 0.5, 0.5, 0.875], [0.375, 0.125, 0.875, 0.875]]
    layout_depth_lr: 0.005
    layout_quat_lr: 0.01
    

  renderer_type: "diff-gaussian-rasterizer-shading"
  renderer:
    debug: false

# ==================== Here we currently do not modify this ====================== #
  material_type: "gaussian-diffuse-with-point-light-material"
  material:
    ambient_only_steps: 300
    textureless_prob: 0.0
    ambient_light_color: [1.0, 1.0, 1.0]
    diffuse_light_color: [0.0, 0.0, 0.0]
    soft_shading: true

  background_type: "gaussian-mvdream-neural-environment-map-background"
  background:
    color_activation: sigmoid
    random_aug: true
    random_aug_prob: 0.5

# Currently still using SD + SDS for layout refinement.
  prompt_processor_type: "stable-diffusion-prompt-processor"
  prompt_processor:
    pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1-base"
    prompt: ???
    negative_prompt: "ugly, bad anatomy, blurry, pixelated obscure, unnatural colors, poor lighting, dull, and unclear, cropped, lowres, low quality, artifacts, duplicate, morbid, mutilated, poorly drawn face, deformed, dehydrated, bad proportions"
    front_threshold: 45.0
    back_threshold: 45.0 # stadarize

  guidance_type: "stable-diffusion-guidance"
  guidance:
    pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1-base"
    guidance_scale: 100.0
    weighting_strategy: sds
    min_step_percent: 0.02
    max_step_percent: [300, 0.98, 0.5, 301]

  exporter_type: "gaussian-mesh-exporter"

  loggers:
    wandb:
      enable: false
      project: 'threestudio'
      name: None

  loss:
    lambda_sds: 0.1
    lambda_position: 1.0
    lambda_opacity: 0.0001
    lambda_scales: 0.0001
    lambda_tv_loss: 1.0
    lambda_depth_tv_loss: 20.0 # 20.0
    lambda_normal_smooth_loss: 100.0 # 100.0
    lambda_feat_recon_loss: 0.0
    lambda_collision: 0.0
    lambda_sparsity: 1.0

  optimizer:
    name: AdamW
    args:
      lr: 0.01
      betas: [0.9, 0.99]
      eps: 1.e-8
    params:
      background:
        lr: 0.001

trainer:
  max_steps: 2000
  log_every_n_steps: 1
  num_sanity_val_steps: 0
  val_check_interval: 100
  enable_progress_bar: true
  precision: 32-true

checkpoint:
  save_last: true # save at each validation time
  save_top_k: -1
  every_n_train_steps: ${trainer.max_steps}
